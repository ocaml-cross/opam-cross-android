--- orig/asmrun/arm.S	2016-11-04 12:08:24.000000000 -0400
+++ patch/asmrun/arm.S	2018-11-14 01:46:38.000000000 -0500
@@ -14,6 +14,74 @@
 /*                                                                        */
 /**************************************************************************/
 
+#if defined(__PIC__)
+
+// YUCK: r3 is not used in any of the ADDRGLOBAL
+#define TMP2 r3
+
+/*
+	ldr	r2, .L3
+.LPIC0:
+	add	r2, pc, r2
+	ldr	r3, .L3+4
+	ldr	r3, [r2, r3]
+	ldr	r3, [r3]
+	mov	r0, r3
+	sub	sp, fp, #0
+	@ sp needed
+	ldr	fp, [sp], #4
+	bx	lr
+.L4:
+	.align	2
+.L3:
+	.word	_GLOBAL_OFFSET_TABLE_-(.LPIC0+8)
+	.word	something(GOT)
+*/	
+#define ADDRGLOBALFULL(reg,_symb,_symb1,_key)                   \
+        push	{TMP2};                                         \
+        ldr     TMP2, .LPIC1##_symb1##_key;                     \
+.LPIC0##_symb1##_key:                                           \
+        add     TMP2, pc, TMP2;                                 \
+        ldr     reg, .LPIC1##_symb1##_key+4;                    \
+        ldr     reg, [TMP2, reg];                               \
+        pop	{TMP2}
+
+//#undef TMP2
+
+#define TABLEGLOBALFULL(_reg_ignore,_symb,_symb1,_key)          \
+	.align	2;						\
+.LPIC1##_symb1##_key:                                           \
+        .word   _GLOBAL_OFFSET_TABLE_-(.LPIC0##_symb1##_key+8); \
+        .word   _symb(GOT)
+
+#else
+
+#define ADDRGLOBALFULL(reg,_symb,_symb1,_key)                   \
+        ldr     reg, =_symb
+
+#define TABLEGLOBALFULL(_reg_ignore,_symb,_symb1,_key)          \
+        /* Nop */
+        
+#endif
+
+#define ADDRGLOBAL(reg,_symb,_key) \
+        ADDRGLOBALFULL(reg,_symb,_symb,_key)
+
+#define TABLEGLOBAL(_reg_ignore, _symb,_key) \
+        TABLEGLOBALFULL(_reg_ignore,_symb,_symb,_key)
+
+#if 0
+/* Not used.
+ */             
+#define LOADGLOBAL(reg,symb) \
+        ADDRGLOBAL(TMP2,symb); \
+        ldr     reg, [TMP2]
+
+#define STOREGLOBAL(reg,symb) \
+        ADDRGLOBAL(TMP2,symb); \
+        str     reg, [TMP2]
+#endif
+
 /* Asm part of the runtime system, ARM processor */
 /* Must be preprocessed by cpp */
 
@@ -116,11 +184,11 @@
         CFI_STARTPROC
         PROFILE
     /* Record return address */
-        ldr     r12, =caml_last_return_address
+        ADDRGLOBAL(r12, caml_last_return_address, 0)
         str     lr, [r12]
 .Lcaml_call_gc:
     /* Record lowest stack address */
-        ldr     r12, =caml_bottom_of_stack
+        ADDRGLOBAL(r12, caml_bottom_of_stack, 0)
         str     sp, [r12]
 #if defined(SYS_linux_eabihf) || defined(SYS_netbsd)
     /* Save caller floating-point registers on the stack */
@@ -129,13 +197,13 @@
     /* Save integer registers and return address on the stack */
         push    {r0-r7,r12,lr}; CFI_ADJUST(40)
     /* Store pointer to saved integer registers in caml_gc_regs */
-        ldr     r12, =caml_gc_regs
+        ADDRGLOBAL(r12, caml_gc_regs, 2)
         str     sp, [r12]
     /* Save current allocation pointer for debugging purposes */
-        ldr     alloc_limit, =caml_young_ptr
+        ADDRGLOBAL(alloc_limit, caml_young_ptr, 0)
         str     alloc_ptr, [alloc_limit]
     /* Save trap pointer in case an exception is raised during GC */
-        ldr     r12, =caml_exception_pointer
+        ADDRGLOBAL(r12, caml_exception_pointer, 0)
         str     trap_ptr, [r12]
     /* Call the garbage collector */
         bl      caml_garbage_collection
@@ -147,7 +215,7 @@
 #endif
     /* Reload new allocation pointer and limit */
     /* alloc_limit still points to caml_young_ptr */
-        ldr     r12, =caml_young_limit
+        ADDRGLOBAL(r12, caml_young_limit, 0)
         ldr     alloc_ptr, [alloc_limit]
         ldr     alloc_limit, [r12]
     /* Return to caller */
@@ -167,7 +235,7 @@
         bcc     1f
         bx      lr
 1:  /* Record return address */
-        ldr     r7, =caml_last_return_address
+        ADDRGLOBAL(r7, caml_last_return_address, 1)
         str     lr, [r7]
     /* Call GC (preserves r7) */
         bl      .Lcaml_call_gc
@@ -190,7 +258,7 @@
         bcc     1f
         bx      lr
 1:  /* Record return address */
-        ldr     r7, =caml_last_return_address
+        ADDRGLOBAL(r7, caml_last_return_address, 2)
         str     lr, [r7]
     /* Call GC (preserves r7) */
         bl      .Lcaml_call_gc
@@ -214,7 +282,7 @@
         bcc     1f
         bx      lr
 1:  /* Record return address */
-        ldr     r7, =caml_last_return_address
+        ADDRGLOBAL(r7, caml_last_return_address, 3)
         str     lr, [r7]
     /* Call GC (preserves r7) */
         bl      .Lcaml_call_gc
@@ -237,12 +305,12 @@
         bcc     1f
         bx      lr
 1:  /* Record return address */
-        ldr     r12, =caml_last_return_address
+        ADDRGLOBAL(r12, caml_last_return_address, 4)
         str     lr, [r12]
     /* Call GC (preserves r7) */
         bl      .Lcaml_call_gc
     /* Restore return address */
-        ldr     r12, =caml_last_return_address
+        ADDRGLOBAL(r12, caml_last_return_address, 5)
         ldr     lr, [r12]
     /* Try again */
         b       .Lcaml_allocN
@@ -259,21 +327,21 @@
         CFI_STARTPROC
         PROFILE
     /* Record lowest stack address and return address */
-        ldr     r5, =caml_last_return_address
-        ldr     r6, =caml_bottom_of_stack
+        ADDRGLOBAL(r5, caml_last_return_address, 6)
+        ADDRGLOBAL(r6, caml_bottom_of_stack, 1)
         str     lr, [r5]
         str     sp, [r6]
     /* Preserve return address in callee-save register r4 */
         mov     r4, lr
     /* Make the exception handler alloc ptr available to the C code */
-        ldr     r5, =caml_young_ptr
-        ldr     r6, =caml_exception_pointer
+        ADDRGLOBAL(r5, caml_young_ptr, 1)
+        ADDRGLOBAL(r6, caml_exception_pointer, 1)
         str     alloc_ptr, [r5]
         str     trap_ptr, [r6]
     /* Call the function */
         blx     r7
     /* Reload alloc ptr and alloc limit */
-        ldr     r6, =caml_young_limit
+        ADDRGLOBAL(r6, caml_young_limit, 1)
         ldr     alloc_ptr, [r5]         /* r5 still points to caml_young_ptr */
         ldr     alloc_limit, [r6]
     /* Return */
@@ -289,8 +357,8 @@
 caml_start_program:
         CFI_STARTPROC
         PROFILE
-        ldr     r12, =caml_program
-
+        ADDRGLOBAL(r12, caml_program, 0)
+        
 /* Code shared with caml_callback* */
 /* Address of OCaml code to call is in r12 */
 /* Arguments to the OCaml code are in r0...r3 */
@@ -304,9 +372,9 @@
         push    {r4-r8,r10,r11,lr}; CFI_ADJUST(32)      /* 8-byte alignment */
     /* Setup a callback link on the stack */
         sub     sp, sp, 16; CFI_ADJUST(16)              /* 8-byte alignment */
-        ldr     r4, =caml_bottom_of_stack
-        ldr     r5, =caml_last_return_address
-        ldr     r6, =caml_gc_regs
+        ADDRGLOBAL(r4, caml_bottom_of_stack, 2)
+        ADDRGLOBAL(r5, caml_last_return_address, 7)
+        ADDRGLOBAL(r6, caml_gc_regs, 0)
         ldr     r4, [r4]
         ldr     r5, [r5]
         ldr     r6, [r6]
@@ -315,39 +383,39 @@
         str     r6, [sp, 8]
     /* Setup a trap frame to catch exceptions escaping the OCaml code */
         sub     sp, sp, 8; CFI_ADJUST(8)
-        ldr     r6, =caml_exception_pointer
-        ldr     r5, =.Ltrap_handler
+        ADDRGLOBAL(r6, caml_exception_pointer, 2)
+        ADDRGLOBALFULL(r5, .Ltrap_handler, Ltrap_handler, 0)
         ldr     r4, [r6]
         str     r4, [sp, 0]
         str     r5, [sp, 4]
         mov     trap_ptr, sp
     /* Reload allocation pointers */
-        ldr     r4, =caml_young_ptr
+        ADDRGLOBAL(r4, caml_young_ptr, 2)
         ldr     alloc_ptr, [r4]
-        ldr     r4, =caml_young_limit
+        ADDRGLOBAL(r4, caml_young_limit, 2)
         ldr     alloc_limit, [r4]
     /* Call the OCaml code */
         blx     r12
 .Lcaml_retaddr:
     /* Pop the trap frame, restoring caml_exception_pointer */
-        ldr     r4, =caml_exception_pointer
+        ADDRGLOBAL(r4, caml_exception_pointer, 3)
         ldr     r5, [sp, 0]
         str     r5, [r4]
         add     sp, sp, 8; CFI_ADJUST(-8)
     /* Pop the callback link, restoring the global variables */
 .Lreturn_result:
-        ldr     r4, =caml_bottom_of_stack
+        ADDRGLOBAL(r4, caml_bottom_of_stack, 3)
         ldr     r5, [sp, 0]
         str     r5, [r4]
-        ldr     r4, =caml_last_return_address
+        ADDRGLOBAL(r4, caml_last_return_address, 8)
         ldr     r5, [sp, 4]
         str     r5, [r4]
-        ldr     r4, =caml_gc_regs
+        ADDRGLOBAL(r4, caml_gc_regs, 1)
         ldr     r5, [sp, 8]
         str     r5, [r4]
         add     sp, sp, 16; CFI_ADJUST(-16)
     /* Update allocation pointer */
-        ldr     r4, =caml_young_ptr
+        ADDRGLOBAL(r4, caml_young_ptr, 3)
         str     alloc_ptr, [r4]
     /* Reload callee-save registers and return address */
         pop     {r4-r8,r10,r11,lr}; CFI_ADJUST(-32)
@@ -368,7 +436,7 @@
 .Ltrap_handler:
         CFI_STARTPROC
     /* Save exception pointer */
-        ldr     r12, =caml_exception_pointer
+        ADDRGLOBAL(r12, caml_exception_pointer, 4)
         str     trap_ptr, [r12]
     /* Encode exception bucket as an exception result */
         orr     r0, r0, 2
@@ -386,7 +454,7 @@
         CFI_STARTPROC
         PROFILE
     /* Test if backtrace is active */
-        ldr     r1, =caml_backtrace_active
+        ADDRGLOBAL(r1, caml_backtrace_active, 0)
         ldr     r1, [r1]
         cbz     r1, 1f
     /* Preserve exception bucket in callee-save register r4 */
@@ -414,21 +482,21 @@
         CFI_STARTPROC
         PROFILE
     /* Reload trap ptr, alloc ptr and alloc limit */
-        ldr     trap_ptr, =caml_exception_pointer
-        ldr     alloc_ptr, =caml_young_ptr
-        ldr     alloc_limit, =caml_young_limit
+        ADDRGLOBAL(trap_ptr, caml_exception_pointer, 5)
+        ADDRGLOBAL(alloc_ptr, caml_young_ptr, 4)
+        ADDRGLOBAL(alloc_limit, caml_young_limit, 3)
         ldr     trap_ptr, [trap_ptr]
         ldr     alloc_ptr, [alloc_ptr]
         ldr     alloc_limit, [alloc_limit]
     /* Test if backtrace is active */
-        ldr     r1, =caml_backtrace_active
+        ADDRGLOBAL(r1, caml_backtrace_active, 1)
         ldr     r1, [r1]
         cbz     r1, 1f
     /* Preserve exception bucket in callee-save register r4 */
         mov     r4, r0
-        ldr     r1, =caml_last_return_address   /* arg2: pc of raise */
+        ADDRGLOBAL(r1, caml_last_return_address, 9) /* arg2: pc of raise */
         ldr     r1, [r1]
-        ldr     r2, =caml_bottom_of_stack       /* arg3: sp of raise */
+        ADDRGLOBAL(r2, caml_bottom_of_stack, 4) /* arg3: sp of raise */
         ldr     r2, [r2]
         mov     r3, trap_ptr                    /* arg4: sp of handler */
         bl      caml_stash_backtrace
@@ -469,7 +537,7 @@
         mov     r0, r1          /* r0 = first arg */
         mov     r1, r2          /* r1 = second arg */
         mov     r2, r12         /* r2 = closure environment */
-        ldr     r12, =caml_apply2
+        ADDRGLOBAL(r12, caml_apply2, 0)
         b       .Ljump_to_caml
         CFI_ENDPROC
         .type   caml_callback2_exn, %function
@@ -487,7 +555,7 @@
         mov     r1, r2          /* r1 = second arg */
         mov     r2, r3          /* r2 = third arg */
         mov     r3, r12         /* r3 = closure environment */
-        ldr     r12, =caml_apply3
+        ADDRGLOBAL(r12, caml_apply3, 0)
         b       .Ljump_to_caml
         CFI_ENDPROC
         .type   caml_callback3_exn, %function
@@ -499,16 +567,58 @@
         CFI_STARTPROC
         PROFILE
     /* Load address of [caml_array_bound_error] in r7 */
-        ldr     r7, =caml_array_bound_error
+        ADDRGLOBAL(r7, caml_array_bound_error, 0)
     /* Call that function */
         b       caml_c_call
         CFI_ENDPROC
         .type   caml_ml_array_bound_error, %function
         .size   caml_ml_array_bound_error, .-caml_ml_array_bound_error
 
+        TABLEGLOBAL(r12, caml_last_return_address, 0)
+        TABLEGLOBAL(r12, caml_bottom_of_stack, 0)
+        TABLEGLOBAL(r12, caml_gc_regs, 2)
+        TABLEGLOBAL(alloc_limit, caml_young_ptr, 0)
+        TABLEGLOBAL(r12, caml_exception_pointer, 0)
+        TABLEGLOBAL(r12, caml_young_limit, 0)
+        TABLEGLOBAL(r7, caml_last_return_address, 1)
+        TABLEGLOBAL(r7, caml_last_return_address, 2)
+        TABLEGLOBAL(r7, caml_last_return_address, 3)
+        TABLEGLOBAL(r12, caml_last_return_address, 4)
+        TABLEGLOBAL(r12, caml_last_return_address, 5)
+        TABLEGLOBAL(r5, caml_last_return_address, 6)
+        TABLEGLOBAL(r6, caml_bottom_of_stack, 1)
+        TABLEGLOBAL(r5, caml_young_ptr, 1)
+        TABLEGLOBAL(r6, caml_exception_pointer, 1)
+        TABLEGLOBAL(r6, caml_young_limit, 1)
+        TABLEGLOBAL(r12, caml_program, 0)
+        TABLEGLOBAL(r4, caml_bottom_of_stack, 2)
+        TABLEGLOBAL(r5, caml_last_return_address, 7)
+        TABLEGLOBAL(r6, caml_gc_regs, 0)
+        TABLEGLOBAL(r6, caml_exception_pointer, 2)
+        TABLEGLOBAL(r4, caml_young_ptr, 2)
+        TABLEGLOBAL(r4, caml_young_limit, 2)
+        TABLEGLOBAL(r4, caml_exception_pointer, 3)
+        TABLEGLOBAL(r4, caml_bottom_of_stack, 3)
+        TABLEGLOBAL(r4, caml_last_return_address, 8)
+        TABLEGLOBAL(r4, caml_gc_regs, 1)
+        TABLEGLOBAL(r4, caml_young_ptr, 3)
+        TABLEGLOBAL(r12, caml_exception_pointer, 4)
+        TABLEGLOBAL(r1, caml_backtrace_active, 0)
+        TABLEGLOBAL(trap_ptr, caml_exception_pointer, 5)
+        TABLEGLOBAL(alloc_ptr, caml_young_ptr, 4)
+        TABLEGLOBAL(alloc_limit, caml_young_limit, 3)
+        TABLEGLOBAL(r1, caml_backtrace_active, 1)
+        TABLEGLOBAL(r1, caml_last_return_address, 9)
+        TABLEGLOBAL(r2, caml_bottom_of_stack, 4)
+        TABLEGLOBAL(r12, caml_apply2, 0)
+        TABLEGLOBAL(r12, caml_apply3, 0)
+        TABLEGLOBAL(r7, caml_array_bound_error, 0)
+        TABLEGLOBALFULL(r5, .Ltrap_handler, Ltrap_handler, 0)
+
         .globl  caml_system__code_end
 caml_system__code_end:
 
+
 /* GC roots for callback */
 
         .data
